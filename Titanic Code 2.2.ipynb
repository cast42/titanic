{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center face=\"verdana\" style=\"color:#6699FF\";font-family:verdana>Utilization of Machine Learning to Predict Titanic Passenger Fate</h1>\n",
    "<h3 align=center>Meera Lakhavani</h3>\n",
    "<h4 align=center>9/25/2015</h4>\n",
    "\n",
    "This Python code follows the data science workflow and implements **logistic regression**, **random forests**, and **support vector machines** from the scikit-learn package to predict survival of passengers onboard the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#6699FF\">1) Read Data</h2>\n",
    "\n",
    "We are given a full set of data (<font face=\"courier\">titanic_full.csv</font>) with information about Titanic passengers and their survival outcome. I utilized pandas to read the .csv file because it allows me to import the file easily and clean it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic_full = pd.read_csv(\"titanic_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I chose to print the first few rows of <font face=\"courier\">titanic_full</font> to insure that it was read properly. This also allows me to glance at possible gaps in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#6699FF\"> 2) Explore Data</h2>\n",
    "\n",
    "Here, I begin an exploration looking for gaps in the data. Specifically I will search for missing and NaN values. I will also start making hypotheses on which factors could influence survival. I will consider the dismissal of variables that are unlikely to have an impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for unique values in categorical variable: embarked\n",
    "# Use this as a tool to seek NaN values\n",
    "print(titanic_full[\"embarked\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 'nan' value is initially seen when searching for unique categorical variables in the \"embarked\" column. In order to have data that can be processed by scikit-learn algorithms, we must fill in these missing values.\n",
    "\n",
    "One approach is to replace missing values with the most commonly occuring value. To find this value, I will use pandas <font face=\"courier\">.value_counts()</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embarked_counts = titanic_full[\"embarked\"].value_counts()\n",
    "embarked_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <font face=\"courier\">.value_counts()</font> command shows us that the vast majority of embarkments were from 'S'. With some confidence, we can fill in NaN values with 'S'.\n",
    "\n",
    "A quick way to continue our exploration is to use <font face=\"courier\">.isnull().any()</font> to return columns that contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return booleans regarding whether the column contains null values\n",
    "titanic_full.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our takeaways from this exploration have given us more clarity on what needs to be cleaned. Specifically, values must be filled in for \"embarked\", \"fare\", and \"age\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2 style=\"color:#6699FF\"> 3) Clean Data</h2>\n",
    "\n",
    "My approach for cleaning the data is as follows:\n",
    "\n",
    "**1. Fill in missing values**\n",
    "* Replace missing age values with median age\n",
    "* Replace missing fare values with median fares\n",
    "* Replace missing categorical values from embarked column with most common occurence (S)\n",
    "\n",
    "**2. Ensure all values are numeric** so that scikit-learn can process and train on the data frame\n",
    "* Binary assignments for gender are suitable (1 and 0)\n",
    "* Embarked codes can be assigned dummy numeric variables\n",
    "\n",
    "**3. Use given information to create useful variables**\n",
    "I decided to create categrorical variables from the name column for titles (Miss., Sir, Captain, etc.) to see if it has an impact on survival.\n",
    "\n",
    "**4. Determine which columns should be ignored as predictors**\n",
    "* Remove columns that have obvious and direct impact on survival (survived, body, boat)\n",
    "* Remove columns with little or no statistical significance (ticket number, cabin, home destination)\n",
    "    * If desired, we can analyze these factors further later (ex. socioeconomic status of destination, cabin proximity to lifeboats)\n",
    "\n",
    "\n",
    "<u>This leaves us with **fare**, **embarked**, **age**, **sex**, **sibsp**, **pclass**, **parch**, and **title** as predictor varibles.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace missing age values with median age\n",
    "titanic_full[\"age\"] = titanic_full[\"age\"].fillna(titanic_full[\"age\"].median())\n",
    "\n",
    "#replace missing fares with median\n",
    "titanic_full[\"fare\"] = titanic_full[\"fare\"].fillna(titanic_full[\"fare\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace missing values with code S\n",
    "titanic_full[\"embarked\"] = titanic_full[\"embarked\"].fillna(\"S\")\n",
    "\n",
    "# Create dummy variables for embarked column -- three new columns with binary responses to category\n",
    "## embarked_dummies = pd.get_dummies(titanic_full['embarked'])\n",
    "\n",
    "# Confirm that the correct columns were created\n",
    "## print embarked_dummies.head(3)\n",
    "\n",
    "# Combine data set with new variable columns in new data frame\n",
    "## titanic_full_new = pd.concat([titanic_full, embarked_dummies], axis=1); titanic_full_new\n",
    "\n",
    "#Confirm that new data frame is correct\n",
    "## list(titanic_full_new.columns.values)\n",
    "\n",
    "# Remove original embarked column now that we have assigned dummy variables\n",
    "# just kidding dont remove yet because dummies arent working\n",
    "#titanic_full_new = titanic_full_new.drop('embarked', 1)\n",
    "\n",
    "# ... until I get my embarked dummy columns to work, we need to convert S, Q, C to numbers\n",
    "\n",
    "# Replace missing values with code S\n",
    "#titanic_full.loc[\"embarked\"] = titanic_full[\"embarked\"].fillna(\"S\")\n",
    "\n",
    "#assign code 0 to S\n",
    "titanic_full.loc[titanic_full[\"embarked\"] == \"S\", \"embarked\"] = 0\n",
    "\n",
    "#assign code 1 to C\n",
    "titanic_full.loc[titanic_full[\"embarked\"] == \"C\", \"embarked\"] = 1\n",
    "\n",
    "#assign code 2 to Q\n",
    "titanic_full.loc[titanic_full[\"embarked\"] == \"Q\", \"embarked\"] = 2\n",
    "\n",
    "# QUESTION FOR JOOLIAN: why when i print this now does it not show in a table like it did before?\n",
    "print titanic_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace all the occurences of male with the number 0, and female with 1\n",
    "titanic_full.loc[titanic_full[\"sex\"] == \"male\", \"sex\"] = 0\n",
    "titanic_full.loc[titanic_full[\"sex\"] == \"female\", \"sex\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was directly inspired by: https://www.dataquest.io/mission/75/improving-your-submission/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ctrl +/ to uncomment the whole thing\n",
    "\n",
    "# # REVISIT THIS COLUMN CREATION BECAUSE IT IS NOT WORKING RIGHT NOW. DO NOT USE TITLE COLUMNS IN TRAINING RN\n",
    "# # No we will create a new column for title\n",
    "# import re\n",
    "\n",
    "# # A function to get the title from a name\n",
    "# def get_title(name):\n",
    "#     # Use a regular expression to search for a title\n",
    "#     #Titles always consist of capital and lowercase letters, and end with a period\n",
    "#     title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "#     # If the title exists, extract and return it\n",
    "#     if title_search:\n",
    "#         return title_search.group(1)\n",
    "#     return \"\"\n",
    "\n",
    "# # Get all the titles and print how often each one occurs\n",
    "# titles = titanic_full_new['name'].apply(get_title)\n",
    "\n",
    "# titanic_full_new = pd.concat([titanic_full, titles], axis=1); titanic_full_new\n",
    "\n",
    "# ##print(pd.value_counts(titles))\n",
    "# print titles.head(2)\n",
    "# print titanic_full_new.head(2)\n",
    "# print titanic_full.head(3)\n",
    "\n",
    "# ##print titanic_full.head(2)\n",
    "\n",
    "# ##title_dummies = pd.get_dummies(titanic_full, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False)\n",
    "\n",
    "# # Create dummy variables for embarked column -- three new columns with binary responses to category\n",
    "# ##embarked_dummies = pd.get_dummies(titanic_full['title'])\n",
    "\n",
    "# # Confirm that the correct columns were created\n",
    "# ##print embarked_dummies.head(5)\n",
    "\n",
    "# # Combine data set with new variable columns in new data frame\n",
    "# ##titanic_full_new = pd.concat([titanic_full, embarked_dummies], axis=1); titanic_full_new\n",
    "\n",
    "# #Confirm that new data frame is correct\n",
    "# ##list(titanic_full_new.columns.values)\n",
    "\n",
    "# #DUMMY VARIABLESS\n",
    "\n",
    "# # Map each title to an integer  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "# #title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "# #for k,v in title_mapping.items():\n",
    "# #    titles[titles == k] = v\n",
    "\n",
    "# # Verify that we converted everything.\n",
    "# #print(pd.value_counts(titles))\n",
    "\n",
    "# # Add in the title column.\n",
    "# #titanic_full[\"title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary columns from new data frame\n",
    "# FIND A CLEANER WAY TO DO THIS\n",
    "# add name and original embarked column to deletion\n",
    "\n",
    "for i in ['home.dest', 'body', 'cabin', 'boat', 'ticket']:\n",
    "    titanic_full.drop(i, 1)\n",
    "\n",
    "    \n",
    "###titanic_full_new = titanic_full_new.drop('home.dest', 1)\n",
    "#titanic_full_new = titanic_full_new.drop('body', 1)\n",
    "#titanic_full_new = titanic_full_new.drop('cabin', 1)\n",
    "#titanic_full_new = titanic_full_new.drop('boat', 1)\n",
    "#titanic_full_new = titanic_full_new.drop('ticket', 1)\n",
    "\n",
    "print titanic_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check to make sure there are now no null values\n",
    "titanic_full.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h2 style=\"color:#6699FF\"> 4) Visualize Data</h2>\n",
    "\n",
    "Here we can utilize plotting tools (IDENTIFY THEM. MAT PLOT LIB. STATSMODELS? SEABORN? PRETTY STUFF) to continue exploring the data and creating hypotheses on which variables will most influence survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# im thinking.. plots of most likely factors survived vs. not. other types of graphs? hmm\n",
    "#correlation graphs between certain variable and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use matplotlib to visualize data with surivival as dependent variable and predictors as independent!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show plots in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram of sibsp\n",
    "titanic_full.sibsp.hist()\n",
    "plt.title('Histogram of Sibsp')\n",
    "plt.xlabel('Number Siblings/Spouses Onboard')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# barplot of sibsp rating grouped by survival (1 or 2)\n",
    "pd.crosstab(titanic_full.sibsp, titanic_full.survived.astype(bool)).plot(kind='bar')\n",
    "plt.title('Sibling/Spouse distrivbution grouped by Survival')\n",
    "plt.xlabel('Numbers of Sibsp')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4D Visualization\n",
    "\n",
    "# from: https://www.kaggle.com/hekkon/titanic/testing/files\n",
    "\n",
    "#not working right now but whatever\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for n,point in train.iterrows():\n",
    "    gender = (1 if point['Male'] else 0 ) + np.random.rand()/10\n",
    "    pclass = point['Pclass'] + np.random.rand()/10\n",
    "    surv = point['Survived'] \n",
    "    third_feature = point['SibSp'] + np.random.rand()/10\n",
    "    color = 'red' if surv else 'blue'\n",
    "\n",
    "    ax.scatter(gender, pclass, third_feature, c=color)\n",
    "\n",
    "ax.set_xlabel('gender')\n",
    "ax.set_ylabel('Pclass')\n",
    "ax.set_zlabel('Sibsp')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('viz.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#6699FF\"> 5) Build Models</h2>\n",
    "\n",
    "Now, onto the juicy stuff! We will train multiple models based on our (predicted to be) important variables and their effect on survival.\n",
    "\n",
    "1. Start by splitting our full test set into a training (70%) and test set (30%)\n",
    "2. Implement **logistic regression**\n",
    "    SUMMARIZE AND EXPAND ON AND KNOW IMPORTANCE OF LOGISTIC REGRESSION\n",
    "3. **Random forests** see above for expansion\n",
    "4. Support vector machines\n",
    "5. Naive bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split full data set for training and testing purposes\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "titanic_train, titanic_test = train_test_split(titanic_full, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u><h4 style=\"color:#6699FF\">Logistic Regression</h4></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data for logistic regression\n",
    "\n",
    "y, x = dmatrices('survived ~ sex + age + sibsp + parch + pclass + fare + embarked',\n",
    "                  titanic_train, return_type=\"dataframe\")\n",
    "\n",
    "y_test, x_test = dmatrices('survived ~ sex + age + sibsp + parch + pclass + fare + embarked',\n",
    "                  titanic_test, return_type=\"dataframe\")\n",
    "\n",
    "print x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flatten y into a 1-D array\n",
    "y = np.ravel(y)\n",
    "\n",
    "# Initiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(x, y)\n",
    "\n",
    "# Check the accuracy on the training set\n",
    "model.score(x_test, y_test['survived'])\n",
    "\n",
    "# add .values to end of x and y variables if this stops running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic regression model #2 in case we want to alter approach/variables\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2 = model2.fit(x, y)\n",
    "\n",
    "# Check the accuracy on the training set\n",
    "model2.score(x_test, y_test['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict class labels for the test set\n",
    "predicted = model2.predict(x_test)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate class probabilities\n",
    "#NOTE TO MEERA: TRY TO UNDERSTAND WHAT EACH OF THESE IS DOING STATISTICALLY\n",
    "probs = model2.predict_proba(x_test)\n",
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate evaluation metrics\n",
    "print metrics.accuracy_score(y_test, predicted)\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u><h4 style=\"color:#6699FF\">Random Forests</h4></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]\n",
    "\n",
    "# Confirm that there are no missing values\n",
    "# is this necessary??\n",
    "for n in predictors:\n",
    "    print n\n",
    "    lista = list(titanic_full_new[n])\n",
    "    print type(lista)\n",
    "    print np.isnan(lista).any()\n",
    "\n",
    "#print titanic_full_new.isnull().any()\n",
    "#print titanic_full_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print titanic_full.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic random forests algorithim\n",
    "# source: https://www.dataquest.io/mission/75/improving-your-submission/\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#put fare back in\n",
    "predictors = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]\n",
    "\n",
    "# n_estimators indicates 100 trees initially\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "#WHY DOSENT THIS WORK \n",
    "scores = cross_validation.cross_val_score(alg, titanic_full[predictors], titanic_full[\"survived\"], cv=3)\n",
    "\n",
    "#nope below\n",
    "#scores2 = cross_validation.cross_val_score(alg, titanic_train, titanic_test, cv=3)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializing our rand forest alg function to improve parameters\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic_full[predictors], titanic_full[\"survived\"], cv=3)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# selecting the best features\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "#implement title into this prediction!!\n",
    "predictors = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic_full[predictors], titanic_full[\"survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the three best features.\n",
    "predictors = [\"pclass\", \"sex\", \"title\", \"fare\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><h4 style=\"color:#6699FF\">Support Vector Machines</h4></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, x = dmatrices('survived ~ sex + age + sibsp + parch + pclass + fare + embarked',\n",
    "                  titanic_train, return_type=\"dataframe\")\n",
    "\n",
    "y_test, x_test = dmatrices('survived ~ sex + age + sibsp + parch + pclass + fare + embarked',\n",
    "                  titanic_test, return_type=\"dataframe\")\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x,y)\n",
    "\n",
    "clf2 = svm.SVC()\n",
    "clf2.fit(x,y)\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><h4 style=\"color:#6699FF\">Naive Bayes</h4></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, x = dmatrices('survived ~ sex + age + sibsp + parch + pclass + fare + embarked',\n",
    "                  titanic_train, return_type=\"dataframe\")\n",
    "\n",
    "y_test, x_test = dmatrices('survived ~ sex + age + sibsp + parch + pclass + fare + embarked',\n",
    "                  titanic_test, return_type=\"dataframe\")\n",
    "\n",
    "y = np.ravel(y)\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x, y)\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "nb_acc = accuracy_score(pred, y_test)\n",
    "print nb_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2 style=\"color:#6699FF\"> 6) Validation of Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict class labels for the test set\n",
    "predicted = model2.predict(x_test)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate class probabilities\n",
    "probs = model2.predict_proba(x_test)\n",
    "print probs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate evaluation metrics\n",
    "print metrics.accuracy_score(y_test, predicted)\n",
    "print metrics.roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print metrics.confusion_matrix(y_test, predicted)\n",
    "print metrics.classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#6699FF\"> &clubs; &hearts; &diams; &spades; </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2 style=\"color:#6699FF\"> 7) Appendix</h2>\n",
    "\n",
    "Sources of code, knowlege, and inspiration:\n",
    "\n",
    "* Karen Xiao\n",
    "* Spencer Allee\n",
    "* Julian Modesto\n",
    "* Norah (Yuan) Shi\n",
    "\n",
    "* https://www.udacity.com/course/intro-to-machine-learning--ud120\n",
    "* https://www.dataquest.io/mission/74/getting-started-with-kaggle/\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* https://www.dataquest.io/mission/75/improving-your-submission/\n",
    "* https://www.kaggle.com/hekkon/titanic/testing\n",
    "* https://www.kaggle.com/benhamner/titanic/python-seaborn-pairplot-example\n",
    "* http://www.myhtmltutorials.com/font.html\n",
    "* https://www.quora.com/Random-Forests/How-do-random-forests-work-in-laymans-terms\n",
    "* http://stackoverflow.com/questions/11587782/creating-dummy-variables-in-pandas-for-python\n",
    "* http://stackoverflow.com/questions/12207326/pandas-frequency-table-for-a-single-variable\n",
    "* http://stackoverflow.com/questions/11587782/creating-dummy-variables-in-pandas-for-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}